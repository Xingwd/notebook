{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考\n",
    "https://python.langchain.com/v0.2/docs/integrations/memory/streamlit_chat_message_history/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import (\n",
    "    StreamlitChatMessageHistory,\n",
    ")\n",
    "\n",
    "history = StreamlitChatMessageHistory(key=\"chat_messages\")\n",
    "\n",
    "history.add_user_message(\"hi!\")\n",
    "history.add_ai_message(\"whats up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, specify your own session_state key for storing messages\n",
    "msgs = StreamlitChatMessageHistory(key=\"special_app_key\")\n",
    "\n",
    "if len(msgs.messages) == 0:\n",
    "    msgs.add_ai_message(\"How can I help you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an AI chatbot having a conversation with a human.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "OPENAI_PROXY = \"https://ip:port\"\n",
    "llm = ChatOpenAI(base_url=OPENAI_PROXY, api_key=\"any\", model=\"gpt-4o\")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: msgs,  # Always return the instance created earlier\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "for msg in msgs.messages:\n",
    "    st.chat_message(msg.type).write(msg.content)\n",
    "\n",
    "if prompt := st.chat_input():\n",
    "    st.chat_message(\"human\").write(prompt)\n",
    "\n",
    "    # As usual, new messages are added to StreamlitChatMessageHistory when the Chain is called.\n",
    "    config = {\"configurable\": {\"session_id\": \"any\"}}\n",
    "    response = chain_with_history.invoke({\"question\": prompt}, config)\n",
    "    st.chat_message(\"ai\").write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run /Users/xingweidong/xwd/envs/python/ai/lib/python3.10/site-packages/ipykernel_launcher.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
